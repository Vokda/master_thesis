Running [1mskepu_ann[m(B with the network [1mciresan_2500_2000_1500_1000_500_10[m(B using the backend [1mopencl[m(B.
output file: networks/ciresan_2500_2000_1500_1000_500_10//data/10000_opencl_1.log
solver: networks/ciresan_2500_2000_1500_1000_500_10/solver.prototxt
Backend set to opencl
Net to be constructed according to networks/ciresan_2500_2000_1500_1000_500_10/net.prototxt
Stochastic gradient descent solver selected.
Overriding solver parameter, using program argument instead: opencl
Backend selected: OpenCL
--------- Constructing network Ciresan 2500x2000x1500x1000x500x10 ---------
Number of layers to create: 13
Creating nodes (meta layers) to be sorted topologically.
Topological Sort: Creating directed acyclical graph from network description.
Topological Sort: Directed acyclic graph created.
Topological Sort: sorting...
done!
Setting meta data...
input layer: mnist
Warning: Parser: unknown data set: data
Parser: resolved unknown dataset.
Dataset used: mnist
done!
Merging layers...
Merging layer tanh1 with hidden1.
Merging layer tanh2 with hidden2.
Merging layer tanh3 with hidden3.
Merging layer tanh4 with hidden4.
Merging layer tanh5 with hidden5.
Removing tanh1
Removing tanh2
Removing tanh3
Removing tanh4
Removing tanh5
done!
Setting deltas...
done!

Topological sort: All done!
Call order result:
mnist -> hidden1(3) -> hidden2(3) -> hidden3(3) -> hidden4(3) -> hidden5(3) -> hidden6(0) -> loss
mnist
D0 <- hidden1 <- D1
D1 <- hidden2 <- D2
D2 <- hidden3 <- D3
D3 <- hidden4 <- D4
D4 <- hidden5 <- D5
D5 <- hidden6 <- D6
D6 <- loss
Creating actual layers from nodes created earlier.
---------- Layer to be constructed: Data ----------
Name of layer: mnist
Data source :mnist
Input layer created.
Allocating space for all images and labels.
Reading training images...
done!
Number of images in total: 60000
Readning training labels...
done!
Number of labels in total: 60000
Reading testing images...
done!
Number of images in total: 60000
Readning testing labels...
done!
Number of labels in total: 60000
Data mapped to "data"
Data mapped to "label"
---------- Layer to be constructed: InnerProduct ----------
Name of layer: hidden1
Activation function set: TanH
Trying to find "data".
"data" found! Storing pointer to data.
Number of weights per neuron: 784
Initalizing weights with uniform distribution.
min -0.05
max 0.05
Initalizing weights with constant distribution.
Data mapped to "ip1"
Number of neurons in layer 2500
---------- Layer to be constructed: InnerProduct ----------
Name of layer: hidden2
Activation function set: TanH
Trying to find "ip1".
"ip1" found! Storing pointer to data.
Number of weights per neuron: 2500
Initalizing weights with uniform distribution.
min -0.05
max 0.05
Initalizing weights with constant distribution.
Data mapped to "ip2"
Number of neurons in layer 2000
---------- Layer to be constructed: InnerProduct ----------
Name of layer: hidden3
Activation function set: TanH
Trying to find "ip2".
"ip2" found! Storing pointer to data.
Number of weights per neuron: 2000
Initalizing weights with uniform distribution.
min -0.05
max 0.05
Initalizing weights with constant distribution.
Data mapped to "ip3"
Number of neurons in layer 1500
---------- Layer to be constructed: InnerProduct ----------
Name of layer: hidden4
Activation function set: TanH
Trying to find "ip3".
"ip3" found! Storing pointer to data.
Number of weights per neuron: 1500
Initalizing weights with uniform distribution.
min -0.05
max 0.05
Initalizing weights with constant distribution.
Data mapped to "ip4"
Number of neurons in layer 1000
---------- Layer to be constructed: InnerProduct ----------
Name of layer: hidden5
Activation function set: TanH
Trying to find "ip4".
"ip4" found! Storing pointer to data.
Number of weights per neuron: 1000
Initalizing weights with uniform distribution.
min -0.05
max 0.05
Initalizing weights with constant distribution.
Data mapped to "ip5"
Number of neurons in layer 500
---------- Layer to be constructed: InnerProduct ----------
Name of layer: hidden6
Activation function set: identity
Trying to find "ip5".
"ip5" found! Storing pointer to data.
Number of weights per neuron: 500
Initalizing weights with uniform distribution.
min -0.05
max 0.05
Initalizing weights with constant distribution.
Data mapped to "ip6"
Number of neurons in layer 10
---------- Layer to be constructed: SoftmaxWithLoss ----------
Name of layer: loss
Trying to find "ip6".
"ip6" found! Storing pointer to data.
Trying to find "label".
"label" found! Storing pointer to data.
label_size 10
Number of layers constructed: 8
NUmber of hidden layers: 6--- Layer creation completed. Setting up layers. ---
--- Setting up layer mnist ---
Delta mapped to "D0"--- Setup for layer mnist completed. ---

--- Setting up layer hidden1 ---
Delta mapped to "D1"Trying to find "D0".
"D0" found! Storing pointer to data.
--- Setup for layer hidden1 completed. ---

--- Setting up layer hidden2 ---
Delta mapped to "D2"Trying to find "D1".
"D1" found! Storing pointer to data.
--- Setup for layer hidden2 completed. ---

--- Setting up layer hidden3 ---
Delta mapped to "D3"Trying to find "D2".
"D2" found! Storing pointer to data.
--- Setup for layer hidden3 completed. ---

--- Setting up layer hidden4 ---
Delta mapped to "D4"Trying to find "D3".
"D3" found! Storing pointer to data.
--- Setup for layer hidden4 completed. ---

--- Setting up layer hidden5 ---
Delta mapped to "D5"Trying to find "D4".
"D4" found! Storing pointer to data.
--- Setup for layer hidden5 completed. ---

--- Setting up layer hidden6 ---
Delta mapped to "D6"Trying to find "D5".
"D5" found! Storing pointer to data.
--- Setup for layer hidden6 completed. ---

--- Setting up layer loss ---
setup delta sender
Trying to find "D6".
"D6" found! Storing pointer to data.
--- Setup for layer loss completed. ---

--------- Network constrution completed ---------
Display data every 100 iteration.
--- Traning network. ---
SGD training of network.
Will train for 10000 number of iterations.
--- Training iteration 0 ---
forward time 0.001707
forward time 0.014773
forward time 0.03505
forward time 0.022869
forward time 0.012741
forward time 0.00577
forward time 0.001195
soft maxed input inf inf inf inf inf inf inf inf inf inf 
target 0 0 0 0 0 1 0 0 0 0 
loss -nan
NETWORK CALCULATION ERROR: loss not finite!
Occured during training iteration 0
output saved to networks/ciresan_2500_2000_1500_1000_500_10//data/10000_opencl_1.log
Run using the solver [1mopencl[m(B: FAILURE!
./single_run: line 43: read: read error: 0: Bad file descriptor
=================================================================================
